{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Synthetic models\n",
    "\n",
    "\n",
    "You are seeing the\n",
    "notebook output generated by\n",
    "[Literate.jl](https://github.com/fredrikekre/Literate.jl) from the\n",
    "[Julia source file](https://github.com/devmotion/Calibration_ICLR2021/blob/main/experiments/src/synthetic/script.jl).\n",
    "The corresponding\n",
    "HTML output can be viewed [here](https://devmotion.github.io/Calibration_ICLR2021/dev/generated/synthetic/),\n",
    "and the plain script output can be found [here](./synthetic.jl).\n",
    "\n",
    "> **Note**\n",
    "> If you want to run the experiments, make sure you have an identical environment.\n",
    "> Please use Julia 1.5.3 and activate and instantiate the environment using\n",
    "> [this Project.toml file](https://github.com/devmotion/Calibration_ICLR2021/blob/main/experiments/src/synthetic/Project.toml)\n",
    "> and [this Manifest.toml file](https://github.com/devmotion/Calibration_ICLR2021/blob/main/experiments/src/synthetic/Manifest.toml).\n",
    ">\n",
    "> [The Github repository](https://github.com/devmotion/Calibration_ICLR2021/) contains\n",
    "> [more detailed instructions](https://github.com/devmotion/Calibration_ICLR2021/blob/main/experiments/README.md) and a\n",
    "> `nix` project environment with a pinned Julia binary for improved reproducibility."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CSV\n",
    "using CairoMakie\n",
    "using CalibrationErrors\n",
    "using CalibrationErrorsDistributions\n",
    "using CalibrationTests\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using FillArrays\n",
    "using ProgressLogging\n",
    "using Query\n",
    "using Showoff\n",
    "using StatsBase\n",
    "\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "using Random\n",
    "\n",
    "using CairoMakie.AbstractPlotting.ColorSchemes: Dark2_8\n",
    "\n",
    "using Logging: with_logger\n",
    "using TerminalLoggers: TerminalLogger\n",
    "\n",
    "# set random seed\n",
    "Random.seed!(1234)\n",
    "\n",
    "# create path before saving\n",
    "function wsavefig(file, fig=current_figure())\n",
    "    mkpath(dirname(file))\n",
    "    return save(file, fig)\n",
    "end\n",
    "\n",
    "# define progress logging frontend\n",
    "const PROGRESSLOGGER = TerminalLogger()\n",
    "\n",
    "# define non-intrusive plotting style\n",
    "set_theme!(\n",
    "    Theme(;\n",
    "        Axis=(\n",
    "            rightspinevisible=false,\n",
    "            topspinevisible=false,\n",
    "            xgridvisible=false,\n",
    "            ygridvisible=false,\n",
    "        ),\n",
    "        Legend=(framevisible=false,),\n",
    "    ),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthetic models\n",
    "\n",
    "We study two setups with $d$-dimensional targets $Y$ and normal distributions $P_X$\n",
    "of the form $\\mathcal{N}(c \\mathbf{1}_d, 0.1^2 \\mathbf{I}_d)$ as predictions,\n",
    "where $c \\sim \\mathrm{U}(0, 1)$.\n",
    "Since calibration analysis is only based on the targets and predicted distributions,\n",
    "we neglect features $X$ in these experiments and specify only the distributions of\n",
    "$Y$ and $P_X$.\n",
    "\n",
    "### Calibrated setup\n",
    "\n",
    "In the first setup we simulate a calibrated model. We achieve this by sampling\n",
    "targets from the predicted distributions, i.e., by defining the conditional distribution\n",
    "of $Y$ given $P_X$ as\n",
    "$$\n",
    "Y \\,|\\, P_X = \\mathcal{N}(\\mu, \\Sigma) \\sim \\mathcal{N}(\\mu, \\Sigma).\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "calibrated_model (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "function calibrated_model(dim::Int, nsamples::Int)\n",
    "    # sample predictions\n",
    "    predictions = [MvNormal(Fill(rand(), dim), 0.1) for _ in 1:nsamples]\n",
    "\n",
    "    # sample targets\n",
    "    targets = map(rand, predictions)\n",
    "\n",
    "    return predictions, targets\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Uncalibrated setup\n",
    "\n",
    "In the second setup we simulate an uncalibrated model of the form\n",
    "$$\n",
    "Y \\,|\\, P_X = \\mathcal{N}(\\mu, \\Sigma) \\sim \\mathcal{N}([0.1, \\mu_2, \\ldots, \\mu_d], \\Sigma).\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "uncalibrated_model (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "function uncalibrated_model(dim::Int, nsamples::Int)\n",
    "    # sample predictions\n",
    "    predictions = [MvNormal(Fill(rand(), dim), 0.1) for _ in 1:nsamples]\n",
    "\n",
    "    # sample targets\n",
    "    targets = map(rand, predictions)\n",
    "    altdist = Normal(0.1, 0.1)\n",
    "    for t in targets\n",
    "        t[1] = rand(altdist)\n",
    "    end\n",
    "\n",
    "    return predictions, targets\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convergence and computation time of estimators\n",
    "\n",
    "We perform an evaluation of the convergence and computation time of the biased estimator\n",
    "$\\widehat{\\mathrm{SKCE}}_k$, the unbiased estimator $\\widehat{\\mathrm{SKCE}}_{k,B}$ with\n",
    "blocks of size $B \\in \\{2, \\sqrt{n}, n\\}$. We use the tensor product kernel\n",
    "$$\n",
    "\\begin{aligned}\n",
    "k\\big((p, y), (p', y')\\big) &= \\exp{\\big(- W_2(p, p')\\big)} \\exp{\\big(-(y - y')^2/2\\big)} \\\\\n",
    "&= \\exp{\\big(-\\sqrt{(m_p - m_{p'})^2 + (\\sigma_p - \\sigma_{p'})^2}\\big)} \\exp{\\big( - (y - y')^2/2\\big)},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $W_2$ is the 2-Wasserstein distance and $m_p, m_{p'}$ and $\\sigma_p, \\sigma_{p'}$\n",
    "denote the mean and the standard deviation of the normal distributions $p$ and $p'$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground truth\n",
    "\n",
    "For both models, we have to \"evaluate\" the true calibration error. Generally, the error\n",
    "depends on the model (and hence also dimension $d$) and the kernel. If the model is\n",
    "calibrated, we know that the calibration error is zero. For the uncalibrated model, we\n",
    "estimate the ground truth with the minimum-variance unbiased estimator as the mean of\n",
    "SKCE estimates for 1000 randomly sampled datasets with 1000 data points."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "true_SKCE (generic function with 2 methods)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "true_SKCE(::typeof(calibrated_model), kernel; dim::Int) = 0.0\n",
    "function true_SKCE(model::typeof(uncalibrated_model), kernel; dim::Int)\n",
    "    estimator = UnbiasedSKCE(kernel)\n",
    "    return mean(calibrationerror(estimator, model(dim, 1_000)...) for _ in 1:1_000)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benchmarking\n",
    "\n",
    "The following two functions implement the benchmarking. We sample 500 datasets of\n",
    "4, 16, 64, 256, and 1024 data points each for the models of dimensions $d=1$ and $d=10$.\n",
    "For each of the datasets, we evaluate the different SKCE estimators. We compute the\n",
    "mean absolute error, the variance, and the minimum computation time for the estimates,\n",
    "grouped by the dimension of the model and the number of samples in the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "benchmark_estimators (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "function benchmark_estimator(estimator, model; dim::Int, nsamples::Int, groundtruth)\n",
    "    # compute the estimator (potentially depending on number of samples)\n",
    "    _estimator = estimator(nsamples)\n",
    "\n",
    "    # cache for calibration error estimates\n",
    "    estimates = Vector{Float64}(undef, 500)\n",
    "\n",
    "    mintime = Inf\n",
    "\n",
    "    name = @sprintf(\"benchmarking (dim = %2d, nsamples = %4d)\", dim, nsamples)\n",
    "    @progress name = name for i in eachindex(estimates)\n",
    "        # sample predictions and targets\n",
    "        predictions, targets = model(dim, nsamples)\n",
    "\n",
    "        # define benchmark function\n",
    "        benchmark_f =\n",
    "            let estimator = _estimator, predictions = predictions, targets = targets\n",
    "                () -> @timed calibrationerror(estimator, predictions, targets)\n",
    "            end\n",
    "\n",
    "        # precompile function\n",
    "        benchmark_f()\n",
    "\n",
    "        # compute calibration error and obtain elapsed time\n",
    "        val, t = benchmark_f()\n",
    "\n",
    "        # only keep minimum execution time\n",
    "        mintime = min(mintime, t)\n",
    "\n",
    "        # save error estimate\n",
    "        estimates[i] = val\n",
    "    end\n",
    "\n",
    "    # save the mean absolute deviation and the variance of the estimates\n",
    "    meanerror = mean(abs(x - groundtruth) for x in estimates)\n",
    "    variance = var(estimates)\n",
    "\n",
    "    return (; dim, nsamples, meanerror, variance, mintime)\n",
    "end\n",
    "\n",
    "function benchmark_estimators(model)\n",
    "    # output file\n",
    "    filename = joinpath(\"data\", \"synthetic\", \"errors_$(model).csv\")\n",
    "\n",
    "    # check if results exist\n",
    "    isfile(filename) && return DataFrame(CSV.File(filename))\n",
    "\n",
    "    # define kernel\n",
    "    kernel = WassersteinExponentialKernel() ⊗ SqExponentialKernel()\n",
    "\n",
    "    # define estimators\n",
    "    estimators = (\n",
    "        \"SKCE\" => _ -> BiasedSKCE(kernel),\n",
    "        \"SKCE (B = 2)\" => _ -> BlockUnbiasedSKCE(kernel, 2),\n",
    "        \"SKCE (B = √n)\" => n -> BlockUnbiasedSKCE(kernel, max(2, Int(floor(sqrt(n))))),\n",
    "        \"SKCE (B = n)\" => _ -> UnbiasedSKCE(kernel),\n",
    "    )\n",
    "\n",
    "    # define number of samples\n",
    "    nsamples = 2 .^ (2:2:10)\n",
    "\n",
    "    # ensure that output directory exists and open file for writing\n",
    "    mkpath(dirname(filename))\n",
    "    open(filename, \"w\") do file\n",
    "        # write headers\n",
    "        println(file, \"estimator,dim,nsamples,meanerror,variance,mintime\")\n",
    "\n",
    "        # for dimensions ``d=1`` and ``d=10``\n",
    "        for d in (1, 10)\n",
    "            # compute/estimate ground truth\n",
    "            groundtruth = true_SKCE(model, kernel; dim=d)\n",
    "\n",
    "            for (i, (name, estimator)) in enumerate(estimators)\n",
    "                # benchmark estimator\n",
    "                @info \"benchmarking estimator: $(name)\"\n",
    "\n",
    "                for n in nsamples\n",
    "                    stats = benchmark_estimator(\n",
    "                        estimator, model; dim=d, nsamples=n, groundtruth=groundtruth\n",
    "                    )\n",
    "\n",
    "                    # save statistics\n",
    "                    print(file, name, \",\")\n",
    "                    join(file, stats, \",\")\n",
    "                    println(file)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # load results\n",
    "    return DataFrame(CSV.File(filename))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "We benchmark the estimators with the calibrated model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40×6 DataFrame\n Row │ estimator      dim    nsamples  meanerror    variance     mintime\n     │ String         Int64  Int64     Float64      Float64      Float64\n─────┼───────────────────────────────────────────────────────────────────────\n   1 │ SKCE               1         4  0.00232646   5.40611e-6   8.39e-7\n   2 │ SKCE               1        16  0.000612749  3.25968e-7   1.1546e-5\n   3 │ SKCE               1        64  0.000160806  2.0837e-8    0.000182119\n   4 │ SKCE               1       256  3.87249e-5   1.37054e-9   0.00293836\n   5 │ SKCE               1      1024  9.62075e-6   7.10919e-11  0.0473988\n   6 │ SKCE (B = 2)       1         4  0.00322484   2.14091e-5   2.48e-7\n   7 │ SKCE (B = 2)       1        16  0.00178976   5.51153e-6   1.318e-6\n   8 │ SKCE (B = 2)       1        64  0.000823384  1.11883e-6   3.404e-6\n  ⋮  │       ⋮          ⋮       ⋮           ⋮            ⋮            ⋮\n  34 │ SKCE (B = √n)     10       256  0.000246347  9.09186e-8   0.000265018\n  35 │ SKCE (B = √n)     10      1024  8.47757e-5   1.10709e-8   0.00208533\n  36 │ SKCE (B = n)      10         4  0.00410328   2.93761e-5   7.2e-7\n  37 │ SKCE (B = n)      10        16  0.000955665  1.41091e-6   1.5352e-5\n  38 │ SKCE (B = n)      10        64  0.000231735  8.77091e-8   0.000260414\n  39 │ SKCE (B = n)      10       256  5.8408e-5    5.31428e-9   0.00424718\n  40 │ SKCE (B = n)      10      1024  1.4255e-5    3.31928e-10  0.0682267\n                                                              25 rows omitted",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>estimator</th><th>dim</th><th>nsamples</th><th>meanerror</th><th>variance</th><th>mintime</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>40 rows × 6 columns</p><tr><th>1</th><td>SKCE</td><td>1</td><td>4</td><td>0.00232646</td><td>5.40611e-6</td><td>8.39e-7</td></tr><tr><th>2</th><td>SKCE</td><td>1</td><td>16</td><td>0.000612749</td><td>3.25968e-7</td><td>1.1546e-5</td></tr><tr><th>3</th><td>SKCE</td><td>1</td><td>64</td><td>0.000160806</td><td>2.0837e-8</td><td>0.000182119</td></tr><tr><th>4</th><td>SKCE</td><td>1</td><td>256</td><td>3.87249e-5</td><td>1.37054e-9</td><td>0.00293836</td></tr><tr><th>5</th><td>SKCE</td><td>1</td><td>1024</td><td>9.62075e-6</td><td>7.10919e-11</td><td>0.0473988</td></tr><tr><th>6</th><td>SKCE (B = 2)</td><td>1</td><td>4</td><td>0.00322484</td><td>2.14091e-5</td><td>2.48e-7</td></tr><tr><th>7</th><td>SKCE (B = 2)</td><td>1</td><td>16</td><td>0.00178976</td><td>5.51153e-6</td><td>1.318e-6</td></tr><tr><th>8</th><td>SKCE (B = 2)</td><td>1</td><td>64</td><td>0.000823384</td><td>1.11883e-6</td><td>3.404e-6</td></tr><tr><th>9</th><td>SKCE (B = 2)</td><td>1</td><td>256</td><td>0.000480282</td><td>3.55902e-7</td><td>1.3808e-5</td></tr><tr><th>10</th><td>SKCE (B = 2)</td><td>1</td><td>1024</td><td>0.000235386</td><td>8.60559e-8</td><td>5.5695e-5</td></tr><tr><th>11</th><td>SKCE (B = √n)</td><td>1</td><td>4</td><td>0.00329201</td><td>2.34735e-5</td><td>2.34e-7</td></tr><tr><th>12</th><td>SKCE (B = √n)</td><td>1</td><td>16</td><td>0.00105996</td><td>1.96389e-6</td><td>2.186e-6</td></tr><tr><th>13</th><td>SKCE (B = √n)</td><td>1</td><td>64</td><td>0.000342314</td><td>1.86192e-7</td><td>2.014e-5</td></tr><tr><th>14</th><td>SKCE (B = √n)</td><td>1</td><td>256</td><td>0.000121204</td><td>2.31226e-8</td><td>0.000173367</td></tr><tr><th>15</th><td>SKCE (B = √n)</td><td>1</td><td>1024</td><td>4.00685e-5</td><td>2.66636e-9</td><td>0.00143577</td></tr><tr><th>16</th><td>SKCE (B = n)</td><td>1</td><td>4</td><td>0.00183983</td><td>8.07962e-6</td><td>5.37e-7</td></tr><tr><th>17</th><td>SKCE (B = n)</td><td>1</td><td>16</td><td>0.000417513</td><td>3.18398e-7</td><td>1.0872e-5</td></tr><tr><th>18</th><td>SKCE (B = n)</td><td>1</td><td>64</td><td>9.96033e-5</td><td>1.92571e-8</td><td>0.000178632</td></tr><tr><th>19</th><td>SKCE (B = n)</td><td>1</td><td>256</td><td>2.48102e-5</td><td>1.25886e-9</td><td>0.00291616</td></tr><tr><th>20</th><td>SKCE (B = n)</td><td>1</td><td>1024</td><td>6.07345e-6</td><td>7.73514e-11</td><td>0.0471831</td></tr><tr><th>21</th><td>SKCE</td><td>10</td><td>4</td><td>0.0236122</td><td>3.94317e-5</td><td>1.104e-6</td></tr><tr><th>22</th><td>SKCE</td><td>10</td><td>16</td><td>0.00590577</td><td>1.67794e-6</td><td>1.6572e-5</td></tr><tr><th>23</th><td>SKCE</td><td>10</td><td>64</td><td>0.00147388</td><td>9.22523e-8</td><td>0.000266736</td></tr><tr><th>24</th><td>SKCE</td><td>10</td><td>256</td><td>0.000368578</td><td>5.66692e-9</td><td>0.00428609</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(100)\n",
    "with_logger(PROGRESSLOGGER) do\n",
    "    benchmark_estimators(calibrated_model)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "We repeat the benchmark with the uncalibrated model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40×6 DataFrame\n Row │ estimator      dim    nsamples  meanerror   variance     mintime\n     │ String         Int64  Int64     Float64     Float64      Float64\n─────┼──────────────────────────────────────────────────────────────────────\n   1 │ SKCE               1         4  0.0751342   0.00996145   8.4e-7\n   2 │ SKCE               1        16  0.0314564   0.00169231   1.1676e-5\n   3 │ SKCE               1        64  0.0159183   0.000394578  0.000184502\n   4 │ SKCE               1       256  0.00802689  0.000102252  0.00295501\n   5 │ SKCE               1      1024  0.00423135  2.77658e-5   0.047851\n   6 │ SKCE (B = 2)       1         4  0.078777    0.00982905   3.54e-7\n   7 │ SKCE (B = 2)       1        16  0.0406132   0.00246662   8.83e-7\n   8 │ SKCE (B = 2)       1        64  0.0194201   0.000600167  3.699e-6\n  ⋮  │       ⋮          ⋮       ⋮          ⋮            ⋮            ⋮\n  34 │ SKCE (B = √n)     10       256  0.00560227  4.84788e-5   0.000258742\n  35 │ SKCE (B = √n)     10      1024  0.00230399  8.42511e-6   0.00214255\n  36 │ SKCE (B = n)      10         4  0.0434448   0.00335596   7.28e-7\n  37 │ SKCE (B = n)      10        16  0.0188946   0.000584298  1.5216e-5\n  38 │ SKCE (B = n)      10        64  0.00994934  0.000150885  0.000263802\n  39 │ SKCE (B = n)      10       256  0.0053346   4.57406e-5   0.00430886\n  40 │ SKCE (B = n)      10      1024  0.00253457  9.91621e-6   0.0692274\n                                                             25 rows omitted",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>estimator</th><th>dim</th><th>nsamples</th><th>meanerror</th><th>variance</th><th>mintime</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>40 rows × 6 columns</p><tr><th>1</th><td>SKCE</td><td>1</td><td>4</td><td>0.0751342</td><td>0.00996145</td><td>8.4e-7</td></tr><tr><th>2</th><td>SKCE</td><td>1</td><td>16</td><td>0.0314564</td><td>0.00169231</td><td>1.1676e-5</td></tr><tr><th>3</th><td>SKCE</td><td>1</td><td>64</td><td>0.0159183</td><td>0.000394578</td><td>0.000184502</td></tr><tr><th>4</th><td>SKCE</td><td>1</td><td>256</td><td>0.00802689</td><td>0.000102252</td><td>0.00295501</td></tr><tr><th>5</th><td>SKCE</td><td>1</td><td>1024</td><td>0.00423135</td><td>2.77658e-5</td><td>0.047851</td></tr><tr><th>6</th><td>SKCE (B = 2)</td><td>1</td><td>4</td><td>0.078777</td><td>0.00982905</td><td>3.54e-7</td></tr><tr><th>7</th><td>SKCE (B = 2)</td><td>1</td><td>16</td><td>0.0406132</td><td>0.00246662</td><td>8.83e-7</td></tr><tr><th>8</th><td>SKCE (B = 2)</td><td>1</td><td>64</td><td>0.0194201</td><td>0.000600167</td><td>3.699e-6</td></tr><tr><th>9</th><td>SKCE (B = 2)</td><td>1</td><td>256</td><td>0.00987522</td><td>0.00015909</td><td>1.4895e-5</td></tr><tr><th>10</th><td>SKCE (B = 2)</td><td>1</td><td>1024</td><td>0.00511378</td><td>4.13817e-5</td><td>6.0314e-5</td></tr><tr><th>11</th><td>SKCE (B = √n)</td><td>1</td><td>4</td><td>0.0811177</td><td>0.0102605</td><td>2.35e-7</td></tr><tr><th>12</th><td>SKCE (B = √n)</td><td>1</td><td>16</td><td>0.0342851</td><td>0.00194094</td><td>2.25e-6</td></tr><tr><th>13</th><td>SKCE (B = √n)</td><td>1</td><td>64</td><td>0.0174102</td><td>0.000456507</td><td>2.0407e-5</td></tr><tr><th>14</th><td>SKCE (B = √n)</td><td>1</td><td>256</td><td>0.00834639</td><td>0.000107721</td><td>0.000175991</td></tr><tr><th>15</th><td>SKCE (B = √n)</td><td>1</td><td>1024</td><td>0.00414902</td><td>2.71046e-5</td><td>0.00146066</td></tr><tr><th>16</th><td>SKCE (B = n)</td><td>1</td><td>4</td><td>0.0714118</td><td>0.00821249</td><td>5.37e-7</td></tr><tr><th>17</th><td>SKCE (B = n)</td><td>1</td><td>16</td><td>0.0342723</td><td>0.00187879</td><td>1.0352e-5</td></tr><tr><th>18</th><td>SKCE (B = n)</td><td>1</td><td>64</td><td>0.0169261</td><td>0.000437577</td><td>0.000178923</td></tr><tr><th>19</th><td>SKCE (B = n)</td><td>1</td><td>256</td><td>0.00838566</td><td>0.000106268</td><td>0.00295301</td></tr><tr><th>20</th><td>SKCE (B = n)</td><td>1</td><td>1024</td><td>0.00426478</td><td>2.90507e-5</td><td>0.047773</td></tr><tr><th>21</th><td>SKCE</td><td>10</td><td>4</td><td>0.0605164</td><td>0.00428938</td><td>1.113e-6</td></tr><tr><th>22</th><td>SKCE</td><td>10</td><td>16</td><td>0.0234032</td><td>0.000668417</td><td>1.6879e-5</td></tr><tr><th>23</th><td>SKCE</td><td>10</td><td>64</td><td>0.0103131</td><td>0.000154495</td><td>0.000271091</td></tr><tr><th>24</th><td>SKCE</td><td>10</td><td>256</td><td>0.00498841</td><td>3.99274e-5</td><td>0.00435522</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(100)\n",
    "with_logger(PROGRESSLOGGER) do\n",
    "    benchmark_estimators(uncalibrated_model)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization\n",
    "\n",
    "We show a visualization of the results below."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "plot_benchmark_estimators (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "function logtickformat(base::Int)\n",
    "    function format(values)\n",
    "        return map(Base.Fix2(logformat, base), showoff(values))\n",
    "    end\n",
    "    return format\n",
    "end\n",
    "\n",
    "function logformat(digits::String, base::Int)\n",
    "    buf = IOBuffer()\n",
    "    print(buf, base)\n",
    "    for c in digits\n",
    "        if '0' ≤ c ≤ '9'\n",
    "            print(buf, Showoff.superscript_numerals[c - '0' + 1])\n",
    "        elseif c == '-'\n",
    "            print(buf, '⁻')\n",
    "        elseif c == '.'\n",
    "            print(buf, '·')\n",
    "        end\n",
    "    end\n",
    "    return String(take!(buf))\n",
    "end\n",
    "\n",
    "function plot_benchmark_estimators(model; dim::Int)\n",
    "    # load and preprocess data\n",
    "    filename = joinpath(\"data\", \"synthetic\", \"errors_$(model).csv\")\n",
    "    groups = @from i in DataFrame(CSV.File(filename)) begin\n",
    "        @where i.dim == dim\n",
    "        @orderby i.nsamples\n",
    "        @select {\n",
    "            i.estimator,\n",
    "            log2_nsamples = log2(i.nsamples),\n",
    "            log10_meanerror = log10(i.meanerror),\n",
    "            log10_variance = log10(i.variance),\n",
    "            log10_mintime = log10(i.mintime),\n",
    "        }\n",
    "        @collect DataFrame\n",
    "    end\n",
    "\n",
    "    # create figure\n",
    "    fig = Figure(; resolution=(960, 800))\n",
    "\n",
    "    # create axes to plot mean error and variance vs number of samples\n",
    "    ax1 = Axis(\n",
    "        fig[1, 1];\n",
    "        xlabel=\"# samples\",\n",
    "        ylabel=\"mean error\",\n",
    "        xticks=2:2:10,\n",
    "        xtickformat=logtickformat(2),\n",
    "        ytickformat=logtickformat(10),\n",
    "    )\n",
    "    ax2 = Axis(\n",
    "        fig[2, 1];\n",
    "        xlabel=\"# samples\",\n",
    "        ylabel=\"variance\",\n",
    "        xticks=2:2:10,\n",
    "        xtickformat=logtickformat(2),\n",
    "        ytickformat=logtickformat(10),\n",
    "    )\n",
    "\n",
    "    # create axes to plot mean error and variance vs timings\n",
    "    ax3 = Axis(\n",
    "        fig[1, 2];\n",
    "        xlabel=\"time [s]\",\n",
    "        ylabel=\"mean error\",\n",
    "        xtickformat=logtickformat(10),\n",
    "        ytickformat=logtickformat(10),\n",
    "    )\n",
    "    ax4 = Axis(\n",
    "        fig[2, 2];\n",
    "        xlabel=\"time [s]\",\n",
    "        ylabel=\"variance\",\n",
    "        xtickformat=logtickformat(10),\n",
    "        ytickformat=logtickformat(10),\n",
    "    )\n",
    "\n",
    "    # plot benchmark results\n",
    "    estimators = [\"SKCE\", \"SKCE (B = 2)\", \"SKCE (B = √n)\", \"SKCE (B = n)\"]\n",
    "    markers = ['●', '■', '▲', '◆']\n",
    "    for (i, (estimator, marker)) in enumerate(zip(estimators, markers))\n",
    "        group = filter(:estimator => ==(estimator), groups)\n",
    "        color = Dark2_8[i]\n",
    "\n",
    "        # plot mean error vs samples\n",
    "        scatterlines!(\n",
    "            ax1,\n",
    "            group.log2_nsamples,\n",
    "            group.log10_meanerror;\n",
    "            color=color,\n",
    "            linewidth=2,\n",
    "            marker=marker,\n",
    "            markercolor=color,\n",
    "        )\n",
    "\n",
    "        # plot variance vs samples\n",
    "        scatterlines!(\n",
    "            ax2,\n",
    "            group.log2_nsamples,\n",
    "            group.log10_variance;\n",
    "            color=color,\n",
    "            linewidth=2,\n",
    "            marker=marker,\n",
    "            markercolor=color,\n",
    "        )\n",
    "\n",
    "        # plot mean error vs time\n",
    "        scatterlines!(\n",
    "            ax3,\n",
    "            group.log10_mintime,\n",
    "            group.log10_meanerror;\n",
    "            color=color,\n",
    "            linewidth=2,\n",
    "            marker=marker,\n",
    "            markercolor=color,\n",
    "        )\n",
    "\n",
    "        # plot variance vs time\n",
    "        scatterlines!(\n",
    "            ax4,\n",
    "            group.log10_mintime,\n",
    "            group.log10_variance;\n",
    "            color=color,\n",
    "            linewidth=2,\n",
    "            marker=marker,\n",
    "            markercolor=color,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    # link axes and hide decorations\n",
    "    linkxaxes!(ax1, ax2)\n",
    "    hidexdecorations!(ax1)\n",
    "    linkxaxes!(ax3, ax4)\n",
    "    hidexdecorations!(ax3)\n",
    "    linkyaxes!(ax1, ax3)\n",
    "    hideydecorations!(ax3)\n",
    "    linkyaxes!(ax2, ax4)\n",
    "    hideydecorations!(ax4)\n",
    "\n",
    "    # add legend\n",
    "    elems = map(1:length(estimators)) do i\n",
    "        [\n",
    "            LineElement(; color=Dark2_8[i], linestyle=nothing, linewidth=2),\n",
    "            MarkerElement(; color=Dark2_8[i], marker=markers[i], strokecolor=:black),\n",
    "        ]\n",
    "    end\n",
    "    Legend(fig[end + 1, :], elems, estimators; orientation=:horizontal, tellheight=true)\n",
    "\n",
    "    return fig\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain the following plots:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot_benchmark_estimators(calibrated_model; dim=1)\n",
    "wsavefig(\"figures/synthetic/estimators_calibrated_model_dim=1.svg\");"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/estimators_calibrated_model_dim=1.svg)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot_benchmark_estimators(calibrated_model; dim=10)\n",
    "wsavefig(\"figures/synthetic/estimators_calibrated_model_dim=10.svg\");"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/estimators_calibrated_model_dim=10.svg)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot_benchmark_estimators(uncalibrated_model; dim=1)\n",
    "wsavefig(\"figures/synthetic/estimators_uncalibrated_model_dim=1.svg\");"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/estimators_uncalibrated_model_dim=1.svg)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot_benchmark_estimators(uncalibrated_model; dim=10)\n",
    "wsavefig(\"figures/synthetic/estimators_uncalibrated_model_dim=10.svg\");"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/estimators_uncalibrated_model_dim=10.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test errors and computation time of calibration tests\n",
    "\n",
    "We fix the significance level $\\alpha = 0.05$.\n",
    "Test predictions are sampled from the same distribution as $P_X$, and test targets are\n",
    "sampled independently from $\\mathcal{N}(0, 0.1^2 \\mathbf{I}_d)$.\n",
    "\n",
    "### Benchmarking"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "benchmark_tests (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "iscalibrated(::typeof(calibrated_model)) = true\n",
    "iscalibrated(::typeof(uncalibrated_model)) = false\n",
    "\n",
    "function benchmark_test(test, model; dim::Int, nsamples::Int)\n",
    "    # number of simulations\n",
    "    nrepeat = 500\n",
    "\n",
    "    # initial values\n",
    "    ntesterrors = 0\n",
    "    mintime = Inf\n",
    "\n",
    "    name = @sprintf(\"benchmarking (dim = %2d, nsamples = %4d)\", dim, nsamples)\n",
    "    @progress name = name for _ in 1:nrepeat\n",
    "        # sample predictions and targets\n",
    "        predictions, targets = model(dim, nsamples)\n",
    "\n",
    "        # define benchmark function\n",
    "        benchmark_f = let test = test, predictions = predictions, targets = targets\n",
    "            () -> @timed pvalue(test(predictions, targets))\n",
    "        end\n",
    "\n",
    "        # precompile function\n",
    "        benchmark_f()\n",
    "\n",
    "        # compute calibration error and obtain elapsed time\n",
    "        val, t = benchmark_f()\n",
    "\n",
    "        # only keep minimum execution time\n",
    "        mintime = min(mintime, t)\n",
    "\n",
    "        # update number of empirical test errors for\n",
    "        # significance level ``\\alpha = 0.05``\n",
    "        ntesterrors += iscalibrated(model) ⊻ (val ≥ 0.05)\n",
    "    end\n",
    "\n",
    "    # compute empirical test error rate\n",
    "    testerror = ntesterrors / nrepeat\n",
    "\n",
    "    return (; dim, nsamples, testerror, mintime)\n",
    "end\n",
    "\n",
    "function benchmark_tests(model)\n",
    "    # output file\n",
    "    filename = joinpath(\"data\", \"synthetic\", \"tests_$(model).csv\")\n",
    "\n",
    "    # check if results exist\n",
    "    isfile(filename) && return DataFrame(CSV.File(filename))\n",
    "\n",
    "    # define kernel\n",
    "    kernel = WassersteinExponentialKernel() ⊗ SqExponentialKernel()\n",
    "\n",
    "    # define number of samples\n",
    "    nsamples = 2 .^ (2:2:10)\n",
    "\n",
    "    # ensure that output directory exists and open file for writing\n",
    "    mkpath(dirname(filename))\n",
    "    open(filename, \"w\") do file\n",
    "        # write headers\n",
    "        println(file, \"test,dim,nsamples,testerror,mintime\")\n",
    "\n",
    "        # for dimensions ``d=1`` and ``d=10``\n",
    "        for d in (1, 10)\n",
    "            # define tests\n",
    "            testpredictions = [MvNormal(rand(d), 0.1) for _ in 1:10]\n",
    "            testtargets = [rand(MvNormal(d, 0.1)) for _ in 1:10]\n",
    "            tests = (\n",
    "                \"SKCE (B = 2)\" =>\n",
    "                    (predictions, targets) -> AsymptoticBlockSKCETest(\n",
    "                        BlockUnbiasedSKCE(kernel, 2), predictions, targets\n",
    "                    ),\n",
    "                \"SKCE (B = √n)\" =>\n",
    "                    (predictions, targets) -> AsymptoticBlockSKCETest(\n",
    "                        BlockUnbiasedSKCE(kernel, Int(floor(sqrt(length(predictions))))),\n",
    "                        predictions,\n",
    "                        targets,\n",
    "                    ),\n",
    "                \"SKCE (B = n)\" =>\n",
    "                    (predictions, targets) ->\n",
    "                        AsymptoticSKCETest(kernel, predictions, targets),\n",
    "                \"CME\" =>\n",
    "                    (predictions, targets) -> AsymptoticCMETest(\n",
    "                        UCME(kernel, testpredictions, testtargets), predictions, targets\n",
    "                    ),\n",
    "            )\n",
    "\n",
    "            for (i, (name, test)) in enumerate(tests)\n",
    "                # benchmark estimator\n",
    "                @info \"benchmarking test: $(name)\"\n",
    "\n",
    "                for n in nsamples\n",
    "                    stats = benchmark_test(test, model; dim=d, nsamples=n)\n",
    "\n",
    "                    # save statistics\n",
    "                    print(file, name, \",\")\n",
    "                    join(file, stats, \",\")\n",
    "                    println(file)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # load results\n",
    "    return DataFrame(CSV.File(filename))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we benchmark the calibrated model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40×5 DataFrame\n Row │ test           dim    nsamples  testerror  mintime\n     │ String         Int64  Int64     Float64    Float64\n─────┼────────────────────────────────────────────────────────\n   1 │ SKCE (B = 2)       1         4      0.128  1.296e-6\n   2 │ SKCE (B = 2)       1        16      0.05   4.202e-6\n   3 │ SKCE (B = 2)       1        64      0.054  1.7021e-5\n   4 │ SKCE (B = 2)       1       256      0.054  6.4322e-5\n   5 │ SKCE (B = 2)       1      1024      0.06   0.000133484\n   6 │ SKCE (B = √n)      1         4      0.134  1.304e-6\n   7 │ SKCE (B = √n)      1        16      0.038  5.944e-6\n   8 │ SKCE (B = √n)      1        64      0.03   4.2991e-5\n  ⋮  │       ⋮          ⋮       ⋮          ⋮           ⋮\n  34 │ SKCE (B = n)      10       256      0.042  0.0513581\n  35 │ SKCE (B = n)      10      1024      0.044  0.796199\n  36 │ CME               10         4      0.478  2.4278e-5\n  37 │ CME               10        16      0.76   4.922e-5\n  38 │ CME               10        64      0.152  7.793e-5\n  39 │ CME               10       256      0.058  0.000260368\n  40 │ CME               10      1024      0.074  0.000988811\n                                               25 rows omitted",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>test</th><th>dim</th><th>nsamples</th><th>testerror</th><th>mintime</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>40 rows × 5 columns</p><tr><th>1</th><td>SKCE (B = 2)</td><td>1</td><td>4</td><td>0.128</td><td>1.296e-6</td></tr><tr><th>2</th><td>SKCE (B = 2)</td><td>1</td><td>16</td><td>0.05</td><td>4.202e-6</td></tr><tr><th>3</th><td>SKCE (B = 2)</td><td>1</td><td>64</td><td>0.054</td><td>1.7021e-5</td></tr><tr><th>4</th><td>SKCE (B = 2)</td><td>1</td><td>256</td><td>0.054</td><td>6.4322e-5</td></tr><tr><th>5</th><td>SKCE (B = 2)</td><td>1</td><td>1024</td><td>0.06</td><td>0.000133484</td></tr><tr><th>6</th><td>SKCE (B = √n)</td><td>1</td><td>4</td><td>0.134</td><td>1.304e-6</td></tr><tr><th>7</th><td>SKCE (B = √n)</td><td>1</td><td>16</td><td>0.038</td><td>5.944e-6</td></tr><tr><th>8</th><td>SKCE (B = √n)</td><td>1</td><td>64</td><td>0.03</td><td>4.2991e-5</td></tr><tr><th>9</th><td>SKCE (B = √n)</td><td>1</td><td>256</td><td>0.02</td><td>0.000180911</td></tr><tr><th>10</th><td>SKCE (B = √n)</td><td>1</td><td>1024</td><td>0.02</td><td>0.00145807</td></tr><tr><th>11</th><td>SKCE (B = n)</td><td>1</td><td>4</td><td>0.142</td><td>8.6026e-5</td></tr><tr><th>12</th><td>SKCE (B = n)</td><td>1</td><td>16</td><td>0.058</td><td>0.00045643</td></tr><tr><th>13</th><td>SKCE (B = n)</td><td>1</td><td>64</td><td>0.04</td><td>0.00403782</td></tr><tr><th>14</th><td>SKCE (B = n)</td><td>1</td><td>256</td><td>0.06</td><td>0.0504854</td></tr><tr><th>15</th><td>SKCE (B = n)</td><td>1</td><td>1024</td><td>0.056</td><td>1.04588</td></tr><tr><th>16</th><td>CME</td><td>1</td><td>4</td><td>0.53</td><td>1.4472e-5</td></tr><tr><th>17</th><td>CME</td><td>1</td><td>16</td><td>0.882</td><td>2.8276e-5</td></tr><tr><th>18</th><td>CME</td><td>1</td><td>64</td><td>0.356</td><td>6.2975e-5</td></tr><tr><th>19</th><td>CME</td><td>1</td><td>256</td><td>0.118</td><td>0.000190426</td></tr><tr><th>20</th><td>CME</td><td>1</td><td>1024</td><td>0.068</td><td>0.000668129</td></tr><tr><th>21</th><td>SKCE (B = 2)</td><td>10</td><td>4</td><td>0.102</td><td>8.0e-7</td></tr><tr><th>22</th><td>SKCE (B = 2)</td><td>10</td><td>16</td><td>0.052</td><td>2.559e-6</td></tr><tr><th>23</th><td>SKCE (B = 2)</td><td>10</td><td>64</td><td>0.064</td><td>1.002e-5</td></tr><tr><th>24</th><td>SKCE (B = 2)</td><td>10</td><td>256</td><td>0.048</td><td>4.0336e-5</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(100)\n",
    "with_logger(PROGRESSLOGGER) do\n",
    "    benchmark_tests(calibrated_model)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "We repeat the analysis with the uncalibrated model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40×5 DataFrame\n Row │ test           dim    nsamples  testerror  mintime\n     │ String         Int64  Int64     Float64    Float64\n─────┼────────────────────────────────────────────────────────\n   1 │ SKCE (B = 2)       1         4      0.648  7.8e-7\n   2 │ SKCE (B = 2)       1        16      0.122  4.424e-6\n   3 │ SKCE (B = 2)       1        64      0.0    1.714e-5\n   4 │ SKCE (B = 2)       1       256      0.0    6.9183e-5\n   5 │ SKCE (B = 2)       1      1024      0.0    0.000138376\n   6 │ SKCE (B = √n)      1         4      0.654  1.364e-6\n   7 │ SKCE (B = √n)      1        16      0.046  3.122e-6\n   8 │ SKCE (B = √n)      1        64      0.0    2.3081e-5\n  ⋮  │       ⋮          ⋮       ⋮          ⋮           ⋮\n  34 │ SKCE (B = n)      10       256      0.0    0.0541269\n  35 │ SKCE (B = n)      10      1024      0.0    0.763799\n  36 │ CME               10         4      0.458  1.8213e-5\n  37 │ CME               10        16      0.004  3.1897e-5\n  38 │ CME               10        64      0.0    7.844e-5\n  39 │ CME               10       256      0.0    0.00026352\n  40 │ CME               10      1024      0.0    0.000995937\n                                               25 rows omitted",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>test</th><th>dim</th><th>nsamples</th><th>testerror</th><th>mintime</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>40 rows × 5 columns</p><tr><th>1</th><td>SKCE (B = 2)</td><td>1</td><td>4</td><td>0.648</td><td>7.8e-7</td></tr><tr><th>2</th><td>SKCE (B = 2)</td><td>1</td><td>16</td><td>0.122</td><td>4.424e-6</td></tr><tr><th>3</th><td>SKCE (B = 2)</td><td>1</td><td>64</td><td>0.0</td><td>1.714e-5</td></tr><tr><th>4</th><td>SKCE (B = 2)</td><td>1</td><td>256</td><td>0.0</td><td>6.9183e-5</td></tr><tr><th>5</th><td>SKCE (B = 2)</td><td>1</td><td>1024</td><td>0.0</td><td>0.000138376</td></tr><tr><th>6</th><td>SKCE (B = √n)</td><td>1</td><td>4</td><td>0.654</td><td>1.364e-6</td></tr><tr><th>7</th><td>SKCE (B = √n)</td><td>1</td><td>16</td><td>0.046</td><td>3.122e-6</td></tr><tr><th>8</th><td>SKCE (B = √n)</td><td>1</td><td>64</td><td>0.0</td><td>2.3081e-5</td></tr><tr><th>9</th><td>SKCE (B = √n)</td><td>1</td><td>256</td><td>0.0</td><td>0.000190658</td></tr><tr><th>10</th><td>SKCE (B = √n)</td><td>1</td><td>1024</td><td>0.0</td><td>0.00156119</td></tr><tr><th>11</th><td>SKCE (B = n)</td><td>1</td><td>4</td><td>0.272</td><td>8.8509e-5</td></tr><tr><th>12</th><td>SKCE (B = n)</td><td>1</td><td>16</td><td>0.0</td><td>0.000477038</td></tr><tr><th>13</th><td>SKCE (B = n)</td><td>1</td><td>64</td><td>0.0</td><td>0.00401854</td></tr><tr><th>14</th><td>SKCE (B = n)</td><td>1</td><td>256</td><td>0.0</td><td>0.0500722</td></tr><tr><th>15</th><td>SKCE (B = n)</td><td>1</td><td>1024</td><td>0.0</td><td>1.10676</td></tr><tr><th>16</th><td>CME</td><td>1</td><td>4</td><td>0.478</td><td>1.5267e-5</td></tr><tr><th>17</th><td>CME</td><td>1</td><td>16</td><td>0.0</td><td>2.5804e-5</td></tr><tr><th>18</th><td>CME</td><td>1</td><td>64</td><td>0.0</td><td>5.7052e-5</td></tr><tr><th>19</th><td>CME</td><td>1</td><td>256</td><td>0.0</td><td>0.000181037</td></tr><tr><th>20</th><td>CME</td><td>1</td><td>1024</td><td>0.0</td><td>0.000668172</td></tr><tr><th>21</th><td>SKCE (B = 2)</td><td>10</td><td>4</td><td>0.748</td><td>7.82e-7</td></tr><tr><th>22</th><td>SKCE (B = 2)</td><td>10</td><td>16</td><td>0.308</td><td>2.543e-6</td></tr><tr><th>23</th><td>SKCE (B = 2)</td><td>10</td><td>64</td><td>0.0</td><td>9.69e-6</td></tr><tr><th>24</th><td>SKCE (B = 2)</td><td>10</td><td>256</td><td>0.0</td><td>7.4793e-5</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(100)\n",
    "with_logger(PROGRESSLOGGER) do\n",
    "    benchmark_tests(uncalibrated_model)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization\n",
    "\n",
    "Again we visualize the results of our benchmarks. However, this time we\n",
    "compare the results for the calibrated and the uncalibrated model in the\n",
    "same plot."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function plot_benchmark_tests(; dim::Int)\n",
    "    # load and preprocess data\n",
    "    df = mapreduce(vcat, (calibrated_model, uncalibrated_model)) do model\n",
    "        filename = joinpath(\"data\", \"synthetic\", \"tests_$(model).csv\")\n",
    "        df = DataFrame(CSV.File(filename))\n",
    "        df[!, :model] .= string(model)\n",
    "        return df\n",
    "    end\n",
    "    groups = @from i in df begin\n",
    "        @where i.dim == dim\n",
    "        @orderby i.nsamples\n",
    "        @select {\n",
    "            i.test,\n",
    "            i.model,\n",
    "            log2_nsamples = log2(i.nsamples),\n",
    "            i.testerror,\n",
    "            log10_mintime = log10(i.mintime),\n",
    "        }\n",
    "        @collect DataFrame\n",
    "    end\n",
    "\n",
    "    # create figure\n",
    "    fig = Figure(; resolution=(960, 400))\n",
    "\n",
    "    # add labels\n",
    "    Label(fig[1:2, 1], \"empirical test error\"; rotation=π / 2, tellheight=false)\n",
    "    Label(fig[1, 2:3, Top()], \"calibrated model\"; padding=(0, 0, 10, 0))\n",
    "    Label(fig[2, 2:3, Top()], \"uncalibrated model\"; padding=(0, 0, 10, 0))\n",
    "\n",
    "    # create axes to plot test error vs number of samples\n",
    "    ax1 = Axis(\n",
    "        fig[1, 2];\n",
    "        ylabel=\"type I error\",\n",
    "        xticks=2:2:10,\n",
    "        xtickformat=logtickformat(2),\n",
    "        xticklabelsize=12,\n",
    "        yticklabelsize=12,\n",
    "    )\n",
    "    ax2 = Axis(\n",
    "        fig[2, 2];\n",
    "        xlabel=\"# samples\",\n",
    "        ylabel=\"type II error\",\n",
    "        xticks=2:2:10,\n",
    "        xtickformat=logtickformat(2),\n",
    "        xticklabelsize=12,\n",
    "        yticklabelsize=12,\n",
    "    )\n",
    "\n",
    "    # create axes to plot test error vs timings\n",
    "    ax3 = Axis(\n",
    "        fig[1, 3]; xtickformat=logtickformat(10), xticklabelsize=12, yticklabelsize=12\n",
    "    )\n",
    "    ax4 = Axis(\n",
    "        fig[2, 3];\n",
    "        xlabel=\"time [s]\",\n",
    "        xtickformat=logtickformat(10),\n",
    "        xticklabelsize=12,\n",
    "        yticklabelsize=12,\n",
    "    )\n",
    "\n",
    "    # plot benchmark results\n",
    "    tests = [\"SKCE (B = 2)\", \"SKCE (B = √n)\", \"SKCE (B = n)\", \"CME\"]\n",
    "    markers = ['●', '■', '▲', '◆']\n",
    "    for (i, (test, marker)) in enumerate(zip(tests, markers))\n",
    "        color = Dark2_8[i]\n",
    "\n",
    "        # for both calibrated and uncalibrated model\n",
    "        for (axes, model) in\n",
    "            zip(((ax1, ax3), (ax2, ax4)), (calibrated_model, uncalibrated_model))\n",
    "            group = filter(x -> x.test == test && x.model == string(model), groups)\n",
    "\n",
    "            # plot test error vs samples\n",
    "            scatterlines!(\n",
    "                axes[1],\n",
    "                group.log2_nsamples,\n",
    "                group.testerror;\n",
    "                color=color,\n",
    "                linewidth=2,\n",
    "                marker=marker,\n",
    "                markercolor=color,\n",
    "            )\n",
    "\n",
    "            # plot test error vs timings\n",
    "            scatterlines!(\n",
    "                axes[2],\n",
    "                group.log10_mintime,\n",
    "                group.testerror;\n",
    "                color=color,\n",
    "                linewidth=2,\n",
    "                marker=marker,\n",
    "                markercolor=color,\n",
    "            )\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # plot horizontal lines for significance level\n",
    "    for axis in (ax1, ax3)\n",
    "        hlines!(axis, 0.05; color=:black, linestyle=:dash, linewidth=2)\n",
    "    end\n",
    "\n",
    "    # link axes and hide decorations\n",
    "    linkxaxes!(ax1, ax2)\n",
    "    hidexdecorations!(ax1)\n",
    "    linkxaxes!(ax3, ax4)\n",
    "    hidexdecorations!(ax3)\n",
    "    linkyaxes!(ax1, ax3)\n",
    "    hideydecorations!(ax3)\n",
    "    linkyaxes!(ax2, ax4)\n",
    "    hideydecorations!(ax4)\n",
    "\n",
    "    # add legend\n",
    "    elems = map(1:length(tests)) do i\n",
    "        [\n",
    "            LineElement(; color=Dark2_8[i], linestyle=nothing, linewidth=2),\n",
    "            MarkerElement(; color=Dark2_8[i], marker=markers[i], strokecolor=:black),\n",
    "        ]\n",
    "    end\n",
    "    push!(elems, [LineElement(; color=:black, linestyle=:dash, linewidth=2)])\n",
    "    Legend(\n",
    "        fig[1:2, end + 1],\n",
    "        elems,\n",
    "        vcat(tests, \"significance level\");\n",
    "        tellwidth=true,\n",
    "        gridshalign=:left,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "end\n",
    "\n",
    "plot_benchmark_tests(; dim=1)\n",
    "wsavefig(\"figures/synthetic/tests_dim=1.svg\");"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/tests_dim=1.svg)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot_benchmark_tests(; dim=10)\n",
    "wsavefig(\"figures/synthetic/tests_dim=10.svg\");"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/synthetic/tests_dim=10.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
